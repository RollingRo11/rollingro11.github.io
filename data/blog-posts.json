[
  {
    "title": "A Primer on Attention Mechanisms",
    "link": "/blog/attention-is-all-you-need/",
    "summary": "A walkthrough of the attention mechanism at the heart of modern language models, from dot-product similarity to multi-head self-attention.",
    "published": "2026-02-15"
  }
]